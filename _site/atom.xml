<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Temiz.ai Research Blog</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2025-07-06T15:46:37+03:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Hüseyin Temiz</name>
   <email></email>
 </author>

 
 <entry>
   <title>3d Meshes And Uv Mapping</title>
   <link href="http://localhost:4000/3d-meshes-and-uv-mapping"/>
   <updated>2025-07-04T00:00:00+03:00</updated>
   <id>http://localhost:4000/3D-Meshes-and-UV-Mapping</id>
   <content type="html">
&lt;p&gt;Meshes and UV maps are core to 3D graphics—they define shape and texture placement. From gaming and film to AR/VR and avatars, understanding how they work together is key to creating realistic and efficient digital content. This blog covers the basics and shows how they’re used in practice.&lt;/p&gt;

&lt;h3 id=&quot;3d-mesh-and-flame&quot;&gt;3D Mesh and FLAME&lt;/h3&gt;

&lt;p&gt;A 3D mesh is a collection of vertices, edges, and faces that define the surface of a 3D object—like a wireframe sculpture. It forms the structural backbone of digital models used in games, animation, simulations, and 3D avatars. Common file formats include .obj, .ply, and .glb. For example, a human face mesh may consist of thousands of vertices and triangular faces to capture fine geometric detail.&lt;/p&gt;

&lt;p&gt;The FLAME [1] model (Faces Learned with an Articulated Model and Expressions) is a widely used parametric 3D head mesh model designed for realistic facial animation. It represents the face with 5023 vertices and 9976 triangles, controlled by identity, expression, and pose parameters. FLAME uses linear blend skinning (LBS) and blendshapes for expressive deformation, making it compact and efficient for applications like 3D avatars, facial reenactment, and neural rendering from 2D images or videos.&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/post002_flame_head.png&quot; alt=&quot;Nearest Neighbor Distance Comparison&quot; width=&quot;50%&quot; /&gt;
&lt;p&gt;&lt;em&gt;Figure 1: FLAME head mesh with different poses.[2]&lt;/em&gt;&lt;/p&gt;  
&lt;/div&gt;

&lt;h3 id=&quot;what-is-uv-mapping&quot;&gt;What Is UV Mapping?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;UV mapping&lt;/strong&gt; is a 2D representation of a 3D surface used for texture mapping. Think of it as creating a flat blueprint of a curved 3D object—like unfolding a globe into a world map or unwrapping a chocolate bar to see its flat wrapper layout.&lt;/p&gt;

&lt;h4 id=&quot;understanding-u-and-v-coordinates&quot;&gt;Understanding U and V Coordinates&lt;/h4&gt;

&lt;p&gt;The letters &lt;strong&gt;U&lt;/strong&gt; and &lt;strong&gt;V&lt;/strong&gt; represent 2D coordinates in texture space, similar to how &lt;strong&gt;X&lt;/strong&gt; and &lt;strong&gt;Y&lt;/strong&gt; work in regular 2D graphics:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;U&lt;/strong&gt; corresponds to the horizontal axis (0 to 1, left to right)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;V&lt;/strong&gt; corresponds to the vertical axis (0 to 1, bottom to top)&lt;/li&gt;
  &lt;li&gt;These coordinates are completely independent from the 3D &lt;strong&gt;XYZ&lt;/strong&gt; coordinates of the mesh&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;the-chocolate-bar-analogy&quot;&gt;The Chocolate Bar Analogy&lt;/h4&gt;

&lt;p&gt;Imagine unwrapping a chocolate bar:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;3D Object&lt;/strong&gt;: The wrapped chocolate bar has a complex curved surface&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;UV Map&lt;/strong&gt;: When you carefully unfold the wrapper, you get a flat 2D layout&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Texture Mapping&lt;/strong&gt;: The printed design on the wrapper (logos, text, patterns) corresponds to how textures are applied to the 3D surface&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This unwrapping process is exactly what UV mapping does—it takes the complex 3D surface and “unfolds” it into a flat 2D space where textures can be painted or applied.&lt;/p&gt;

&lt;h4 id=&quot;why-uv-coordinates&quot;&gt;Why UV Coordinates?&lt;/h4&gt;

&lt;p&gt;UV coordinates are normalized (0 to 1 range), making them resolution-independent. Whether your texture is 256×256 pixels or 4096×4096 pixels, the same UV coordinates will work perfectly.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;images/post002_flame_uv_wireframe.png&quot; alt=&quot;Nearest Neighbor Distance Comparison&quot; width=&quot;50%&quot; /&gt;
&lt;p&gt;&lt;em&gt;Figure 2: UV MAP of FLAME.&lt;/em&gt;&lt;/p&gt;  
&lt;/div&gt;

&lt;h3 id=&quot;how-flame-mesh-and-uv-map-work-together&quot;&gt;How FLAME Mesh and UV Map Work Together&lt;/h3&gt;

&lt;p&gt;The FLAME model provides a 3D mesh of the human head, defined by &lt;strong&gt;5023 vertices&lt;/strong&gt; and &lt;strong&gt;9976 triangular faces&lt;/strong&gt;, while the pre-calculated UV map offers a 2D representation of that mesh surface. The &lt;strong&gt;matching&lt;/strong&gt; between the FLAME mesh and its UV map is defined by a &lt;strong&gt;per-vertex correspondence&lt;/strong&gt;, where each vertex in 3D space has an associated &lt;strong&gt;(u, v)&lt;/strong&gt; coordinate in 2D UV space.&lt;/p&gt;

&lt;p&gt;Here’s how the matching works:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Each triangle in the FLAME mesh consists of 3 vertices indexed in 3D space.&lt;/li&gt;
  &lt;li&gt;The same triangle has corresponding UV coordinates for those 3 vertices in 2D.&lt;/li&gt;
  &lt;li&gt;When rendering or texturing, the &lt;strong&gt;3D triangle&lt;/strong&gt; is mapped to its &lt;strong&gt;2D counterpart&lt;/strong&gt; using these UV coordinates.&lt;/li&gt;
  &lt;li&gt;This mapping allows a 2D texture image to wrap seamlessly over the 3D mesh surface.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In practice, you often have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;strong&gt;vertex list&lt;/strong&gt;: 3D coordinates (x, y, z) for each vertex.&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;face list&lt;/strong&gt;: triplets of vertex indices (defining triangles).&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;UV list&lt;/strong&gt;: (u, v) coordinates per vertex.&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;UV face list&lt;/strong&gt;: triplets of UV indices (corresponding to vertex indices in face list).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, the structure allows the renderer or processing tool to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Match each triangle’s 3D geometry to its corresponding UV triangle.&lt;/li&gt;
  &lt;li&gt;Sample texture values from the UV space during rendering or neural feature mapping (e.g., in 3DGS or GEM).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;techniques-for-uv-mapping&quot;&gt;Techniques for UV Mapping&lt;/h3&gt;

&lt;p&gt;UV mapping can be done manually using tools like Blender or Maya for precise control, or automatically for faster results. Good UV maps minimize distortion and avoid stretching by carefully placing seams and organizing UV islands. Clean mapping is key for accurate texture placement and visual quality.&lt;/p&gt;

&lt;h3 id=&quot;why-uv-mapping-matters&quot;&gt;Why UV Mapping Matters&lt;/h3&gt;

&lt;p&gt;UV mapping is essential for applying textures, PBR materials, baked normals, and lightmaps, enabling detailed and stylized 3D visuals. It also plays a key role in neural rendering, such as mapping 3D Gaussians onto UV space for efficient and high-fidelity avatar synthesis.&lt;/p&gt;

&lt;h3 id=&quot;tools-and-code-snippets&quot;&gt;Tools and Code Snippets&lt;/h3&gt;

&lt;p&gt;Tools like Trimesh and Open3D allow easy access to mesh geometry and UV coordinates in code. You can use them to load meshes, extract UVs, and sample points on the UV map for tasks like texture transfer or feature alignment. Advanced techniques like Poisson disk sampling on the UV map enable uniform point distribution, useful for generative models and neural rendering pipelines.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Mesh and UV mapping form the foundation of 3D graphics, enabling detailed geometry and rich texture placement across digital models. Whether you’re working on games, films, or avatars, mastering these concepts is essential. Try loading a simple mesh and unwrapping it yourself to see how UVs bring textures to life—tools like Blender or code notebooks make it easy to get started.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;[1] Li, Tianye, Timo Bolkart, Michael J. Black, Hao Li, and Javier Romero. “Learning a model of facial shape and expression from 4D scans.” ACM Trans. Graph. 2017.&lt;/p&gt;

&lt;p&gt;[2] https://github.com/TimoBolkart/FLAME-Universe&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Placing Gaussians Splats On Mesh Surface</title>
   <link href="http://localhost:4000/placing-gaussians-splats-on-mesh-surface"/>
   <updated>2025-07-03T00:00:00+03:00</updated>
   <id>http://localhost:4000/Placing-Gaussians-Splats-on-Mesh-Surface</id>
   <content type="html">&lt;!-- ## Placing Gaussians on Mesh Surface --&gt;

&lt;p&gt;In recent years, 3D Gaussian Splatting (GS) has emerged as a powerful technique for photorealistic avatar rendering and animation. Optimizing Gaussian splats without any geometric prior is challenging, as they often fail to regress accurate geometry. However, when the geometry of the object is known, fitting a mesh in advance and using its surface as a geometric prior provides a significant advantage. For example, if the object to be reconstructed is a human head, leveraging the FLAME mesh model as a geometric prior can greatly improve results.&lt;/p&gt;

&lt;p&gt;After fitting the FLAME model, we obtain a reasonable geometric surface on which to place GSs. At this stage, how we distribute the GSs on the mesh becomes an important problem. Using a smart strategy to place the GSs on the surface can significantly aid the subsequent GS optimization process.&lt;/p&gt;

&lt;h3 id=&quot;naïve-random-sampling&quot;&gt;Naïve Random Sampling&lt;/h3&gt;

&lt;p&gt;As a baseline, GSs can be randomly distributed across the mesh surface. However, this naive approach often leads to &lt;strong&gt;clustering&lt;/strong&gt;, &lt;strong&gt;irregular spacing&lt;/strong&gt;, and &lt;strong&gt;oversampling&lt;/strong&gt;, which degrades both visual quality and optimization stability.&lt;/p&gt;

&lt;h3 id=&quot;poisson-disk-sampling&quot;&gt;Poisson Disk Sampling&lt;/h3&gt;

&lt;p&gt;To avoid the performance degradations of random sampling, &lt;strong&gt;Poisson Disk Sampling&lt;/strong&gt; — a technique that enforces a minimum distance between sampled points — to robustly distribute Gaussians on the FLAME mesh.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Poisson Disk Sampling Algorithm (Bridson’s Algorithm)&lt;/strong&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize a grid with cell size = r/√2 (where r is minimum distance)&lt;/li&gt;
  &lt;li&gt;Start with a random initial point, add to active list&lt;/li&gt;
  &lt;li&gt;While active list is not empty:
    &lt;ul&gt;
      &lt;li&gt;Pick random point from active list&lt;/li&gt;
      &lt;li&gt;Generate k candidates (typically k=30) in annulus [r, 2r]&lt;/li&gt;
      &lt;li&gt;For each candidate:&lt;/li&gt;
    &lt;/ul&gt;
    &lt;ul&gt;
      &lt;li&gt;Check if it’s far enough from all neighbors&lt;/li&gt;
      &lt;li&gt;If valid, add to output and active list
      - If no valid candidates found, remove point from active list&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Key Properties&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Guarantees minimum distance r between all points&lt;/li&gt;
  &lt;li&gt;Maximum distance approximately 2r&lt;/li&gt;
  &lt;li&gt;O(n) time complexity&lt;/li&gt;
  &lt;li&gt;Produces uniform, organic-looking distributions&lt;/li&gt;
&lt;/ul&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/images/post001_algorithm_comparison.png&quot; alt=&quot;Algorithm Comparison&quot; width=&quot;70%&quot; /&gt;
  &lt;p&gt;&lt;em&gt; Figure 1: A side-by-side comparison of random sampling (left) and Poisson disk sampling (right) on a 2D surface.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;!-- /Users/huseyintemiz/Documents/temiz_ai_dev/poisson_disk/experiments1/run_visualization.py --&gt;

&lt;p&gt;Figure 1 shows the comparison between the two sampling methods, highlighting how Poisson Disk Sampling achieves more consistent nearest neighbor distances (lower standard deviation) and avoids extreme clustering (higher minimum distance) compared to random sampling.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/images/post001_sampling_comparison.png&quot; alt=&quot;Sampling Comparison on Surface&quot; width=&quot;70%&quot; /&gt;
    &lt;p&gt;&lt;em&gt;Figure 2: Comparison between random sampling (left) and Poisson disk sampling (right) on a sphere surface.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;As Figure 2 shows, Poisson disk sampling provides significantly better surface coverage compared to random sampling. The uniform distribution of sample points ensures that no regions of the mesh are left sparsely covered, while simultaneously preventing overcrowding in other areas. This improved coverage translates directly to more consistent Gaussian placement across the entire FLAME mesh surface, resulting in better geometric representation and more stable optimization during the 3D Gaussian splatting process.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/images/post001_nn_distance_comparison.png&quot; alt=&quot;Nearest Neighbor Distance Comparison&quot; width=&quot;50%&quot; /&gt;
&lt;p&gt;&lt;em&gt;Figure 3: Nearest neighbor distance distributions for different samplings on sphere surface.&lt;/em&gt;&lt;/p&gt;  
&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Metric&lt;/th&gt;
      &lt;th&gt;Poisson Disk Sampling&lt;/th&gt;
      &lt;th&gt;Random Sampling&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;n_points&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;500&lt;/td&gt;
      &lt;td&gt;500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;nn_mean&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;0.1187&lt;/td&gt;
      &lt;td&gt;0.0787&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;nn_std&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;0.0160&lt;/td&gt;
      &lt;td&gt;0.0418&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;nn_min&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;0.1001&lt;/td&gt;
      &lt;td&gt;0.0073&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;nn_max&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;0.1853&lt;/td&gt;
      &lt;td&gt;0.2509&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Table 1: Nearest neighbor distance statistics comparison between Poisson Disk Sampling and Random Sampling methods.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The quantitative analysis in Table 1 and the distribution visualization in Figure 3 clearly demonstrate the superiority of Poisson Disk Sampling over random sampling. Most notably, Poisson Disk Sampling maintains a &lt;strong&gt;significantly higher minimum distance&lt;/strong&gt; (0.1001 vs 0.0073), preventing the extreme clustering that occurs with random sampling. The &lt;strong&gt;lower standard deviation&lt;/strong&gt; (0.0160 vs 0.0418) indicates much more consistent spacing between neighboring Gaussians, while the &lt;strong&gt;constrained maximum distance&lt;/strong&gt; (0.1853 vs 0.2509) ensures no large gaps in coverage. This uniform distribution is crucial for stable 3D Gaussian Splatting optimization, as it prevents both overcrowded regions that cause rendering artifacts and sparse areas that miss geometric detail.&lt;/p&gt;

&lt;h3 id=&quot;sampling-on-flame-mesh&quot;&gt;Sampling on FLAME mesh&lt;/h3&gt;

&lt;p&gt;Figures 2 and 3 illustrate performance on a spherical surface with a more uniform geometry. In real-world applications, geometry is far from trivial—the FLAME human head mesh is both highly realistic and sufficiently complex. We will evaluate the sampling methods’ performance on the FLAME model.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/images/post001_flame_sampling_comparison.png&quot; alt=&quot;Nearest Neighbor Distance Comparison&quot; width=&quot;50%&quot; /&gt;
&lt;p&gt;&lt;em&gt;Figure 4: Nearest neighbor distance distributions for different samplings.&lt;/em&gt;&lt;/p&gt;  
&lt;/div&gt;

&lt;p&gt;Figure 4 visually compares random and Poisson disk sampling on the FLAME mesh for different point counts. Poisson disk sampling (bottom row, red) produces a much more uniform and evenly spaced distribution of points across the surface, as reflected by higher uniformity scores. In contrast, random sampling (top row, blue) results in visible clustering and uneven coverage, regardless of the number of points. This demonstrates that Poisson disk sampling maintains consistent regularity and superior surface coverage.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/images/post001_flame_nn_distance_histograms.png&quot; alt=&quot;Nearest Neighbor Distance Comparison&quot; width=&quot;50%&quot; /&gt;
&lt;p&gt;&lt;em&gt;Figure 5: Nearest Neihbor distance distribution of different sampling experiments.&lt;/em&gt;&lt;/p&gt;  
&lt;/div&gt;

&lt;p&gt;In Figure 5, Poisson disk sampling consistently enforces a minimum distance between neighboring samples, as shown by the sharp cutoff on the left side of each distribution. This property prevents samples from clustering too closely or overlapping, resulting in a more uniform and controlled distribution across the surface. In contrast, random sampling produces a broader spread of nearest neighbor distances, with many samples packed very closely together, leading to potential overlaps and uneven coverage. As the number of points increases, Poisson sampling maintains this regularity, while random sampling continues to exhibit significant variability and clustering. This highlights the robustness of Poisson disk sampling for applications requiring uniform coverage.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/images/post001_flame_sampling_statistics.png&quot; alt=&quot;Nearest Neighbor Distance Comparison&quot; width=&quot;50%&quot; /&gt;
&lt;p&gt;&lt;em&gt;Figure 6: flame_sampling_statistics.png.&lt;/em&gt;&lt;/p&gt;  
&lt;/div&gt;

&lt;p&gt;The Uniformity Score is a metric that quantifies how evenly points are distributed in a sampling. It is calculated as 1 minus the coefficient of variation (CV) of the nearest neighbor distances, where CV is the standard deviation divided by the mean. A score closer to 1 indicates a more uniform (evenly spaced) distribution, while a lower score means greater variability and less uniformity. This makes it easy to compare different sampling methods: for example, Poisson disk sampling yields higher uniformity scores than random sampling, reflecting its more consistent spacing between points.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Points&lt;/th&gt;
      &lt;th&gt;Random Sampling&lt;/th&gt;
      &lt;th&gt;Poisson Disk Sampling&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1000&lt;/td&gt;
      &lt;td&gt;0.4906&lt;/td&gt;
      &lt;td&gt;0.7752&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;0.4760&lt;/td&gt;
      &lt;td&gt;0.8107&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10000&lt;/td&gt;
      &lt;td&gt;0.4795&lt;/td&gt;
      &lt;td&gt;0.8086&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Table 2: Uniformity scores (higher is better) for random and Poisson disk sampling at different point counts.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Table 2 clearly shows that Poisson disk sampling consistently achieves much higher uniformity scores than random sampling across all point counts. This indicates that Poisson disk sampling produces a more evenly spaced and regular distribution of points on the mesh surface, while random sampling results in greater variability and less uniform coverage. The higher uniformity of Poisson disk sampling is especially important for applications that require consistent surface representation and stable optimization.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;For placing Gaussians on mesh surfaces, uniform coverage, minimal overlap, adaptive density, and mesh-awareness are essential. Naïve random sampling often leads to clustering, gaps, and unstable optimization. In contrast, Poisson Disk Sampling enforces even spacing and respects mesh geometry, resulting in a more regular and robust distribution. Having better geometric priors at the start of Gaussian splat optimization leads to more accurate and consistent recovery of visual details. This approach enables more accurate and stable neural avatar representations, improving rendering quality and optimization convergence—especially for complex models and advanced techniques such as GEM, RGBAvatar, or 3D Gaussian Blendshapes.&lt;/p&gt;

&lt;!-- #### to-do list
- poisson disk sampling logic/algorithm
- complexity check
- PD init GS vs Random init GS (compare metrics) --&gt;

</content>
 </entry>
 
 <entry>
   <title>Sample Math Latex Code</title>
   <link href="http://localhost:4000/sample-math-latex-code"/>
   <updated>2025-05-20T00:00:00+03:00</updated>
   <id>http://localhost:4000/sample-math-latex-code</id>
   <content type="html">&lt;!-- # Spherical Harmonics in Gaussian Splats --&gt;

&lt;p&gt;This is experimental page. All contents are garbage.&lt;/p&gt;

&lt;!-- ## 🔸 Why Use Spherical Harmonics in Gaussian Splats? --&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;assets/images/post000_set-of-spherical-harmonics-mapped-to-the-surface-of-a-sphere.png&quot; alt=&quot;Set of spherical harmonics mapped to the surface of a sphere&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;em&gt;Set of spherical harmonics mapped to the surface of a sphere&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When rendering 3D scenes using Gaussian splats, each point (or “splat”) needs to represent not just &lt;strong&gt;color&lt;/strong&gt;, but how that color &lt;strong&gt;changes depending on the viewing direction&lt;/strong&gt;. Spherical harmonics allow encoding this angular variation compactly.&lt;/p&gt;

&lt;p&gt;This is important for achieving &lt;strong&gt;photorealistic rendering&lt;/strong&gt; with effects like:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Specular highlights&lt;/li&gt;
  &lt;li&gt;Soft shadows&lt;/li&gt;
  &lt;li&gt;View-dependent lighting changes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-what-are-spherical-harmonics&quot;&gt;🔸 What Are Spherical Harmonics?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Spherical Harmonics (SH)&lt;/strong&gt; are a series of &lt;strong&gt;orthogonal basis functions&lt;/strong&gt; defined on the surface of a sphere. You can think of them as the 3D analog of &lt;strong&gt;Fourier series&lt;/strong&gt; for functions on a sphere.&lt;/p&gt;

&lt;p&gt;They are indexed by:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Degree (l)&lt;/strong&gt;: controls the frequency (higher means more detail)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Order (m)&lt;/strong&gt;: varies from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-l&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+l&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-levels&quot;&gt;Example Levels:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SH level 0 (SH0):&lt;/strong&gt; Only constant color (no view dependence)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SH level 1 (SH1):&lt;/strong&gt; Basic directional lighting (like Lambertian)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SH level 2 or 3+:&lt;/strong&gt; Captures more complex angular dependencies&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-sh-in-gaussian-splatting&quot;&gt;🔸 SH in Gaussian Splatting&lt;/h2&gt;

&lt;p&gt;Each 3D Gaussian stores:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Position, scale, rotation, opacity&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Spherical Harmonics coefficients for RGB appearance&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Instead of storing just a single RGB color, we store a &lt;strong&gt;set of SH coefficients per color channel&lt;/strong&gt;. When rendering:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Compute the &lt;strong&gt;viewing direction&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt; for each Gaussian.&lt;/li&gt;
  &lt;li&gt;Evaluate the &lt;strong&gt;SH basis functions&lt;/strong&gt; at direction &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt; to get a vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SH_basis(v)&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Compute the final color as a dot product:&lt;/li&gt;
&lt;/ol&gt;

\[C(v) = \sum_{l=0}^{L} \sum_{m=-l}^{l} c_{l,m} \cdot Y_{l,m}(v)\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(C(v)\) : The final color for the viewing direction \(v\).&lt;/li&gt;
  &lt;li&gt;\(c_{l,m}\): The SH coefficients for each degree \(l\) and order \(m\).&lt;/li&gt;
  &lt;li&gt;\(Y_{l,m}(v)\): The SH basis functions evaluated at the direction \(v\).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-key-spherical-harmonics-equations&quot;&gt;🔸 Key Spherical Harmonics Equations&lt;/h2&gt;

&lt;h3 id=&quot;sh-basis-functions&quot;&gt;SH Basis Functions&lt;/h3&gt;

&lt;p&gt;The real-valued spherical harmonics basis functions are defined as:&lt;/p&gt;

\[Y_{l}^{m}(\theta, \phi) = N_{l}^{m} \cdot P_{l}^{m}(\cos\theta) \cdot 
\begin{cases}
\sqrt{2} \sin(|m|\phi) &amp;amp; \text{if } m &amp;lt; 0 \\
1 &amp;amp; \text{if } m = 0 \\
\sqrt{2} \cos(m\phi) &amp;amp; \text{if } m &amp;gt; 0
\end{cases}\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\theta\) : inclination (angle from the z-axis)&lt;/li&gt;
  &lt;li&gt;\(\phi\): azimuth (angle from the x-axis in the x-y plane)&lt;/li&gt;
  &lt;li&gt;\(N_{l}^{m}\): normalization constant&lt;/li&gt;
  &lt;li&gt;\(P_{l}^{m}\): associated Legendre polynomial&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;normalization-constant&quot;&gt;Normalization Constant&lt;/h3&gt;

\[N_{l}^{m} = \sqrt{\frac{(2l+1)}{4\pi} \cdot \frac{(l - |m|)!}{(l + |m|)!}}\]

&lt;h3 id=&quot;example-sh0-and-sh1&quot;&gt;Example: SH0 and SH1&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;SH0 (l=0, m=0):&lt;/strong&gt;
  \(Y_0^0 = \frac{1}{2} \sqrt{\frac{1}{\pi}}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SH1 (l=1, m=-1,0,1):&lt;/strong&gt;
  \(Y_1^{-1} = \sqrt{\frac{3}{4\pi}} \sin\theta \sin\phi\)
  \(Y_1^{0} = \sqrt{\frac{3}{4\pi}} \cos\theta\)
  \(Y_1^{1} = \sqrt{\frac{3}{4\pi}} \sin\theta \cos\phi\)
    &lt;h2 id=&quot;-benefits-of-using-sh&quot;&gt;🔸 Benefits of Using SH&lt;/h2&gt;
  &lt;/li&gt;
  &lt;li&gt;Compact representation of angular variation.&lt;/li&gt;
  &lt;li&gt;Efficient evaluation during rendering.&lt;/li&gt;
  &lt;li&gt;Scalable to higher levels for more detail.&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Spherical Harmonics In Gaussian Splats</title>
   <link href="http://localhost:4000/spherical-harmonics-in-gaussian-splats"/>
   <updated>2025-05-19T00:00:00+03:00</updated>
   <id>http://localhost:4000/Spherical-Harmonics-in-Gaussian-Splats</id>
   <content type="html">
&lt;!-- # Spherical Harmonics in Gaussian Splats --&gt;

&lt;h2 id=&quot;-why-use-spherical-harmonics-in-gaussian-splats&quot;&gt;🔸 Why Use Spherical Harmonics in Gaussian Splats?&lt;/h2&gt;

&lt;p&gt;When rendering 3D scenes using Gaussian splats, each point (or “splat”) needs to represent not just &lt;strong&gt;color&lt;/strong&gt;, but how that color &lt;strong&gt;changes depending on the viewing direction&lt;/strong&gt;. Spherical harmonics allow encoding this angular variation compactly.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;assets/images/post000_set-of-spherical-harmonics-mapped-to-the-surface-of-a-sphere.png&quot; alt=&quot;Set of spherical harmonics mapped to the surface of a sphere&quot; width=&quot;300&quot; /&gt;
    &lt;img src=&quot;assets/images/post000_Spherical_Harmonics.png&quot; alt=&quot;Spherical Harmonics visualization&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;em&gt;Left: Spherical harmonics mapped to a sphere &amp;nbsp;&amp;nbsp;|&amp;nbsp;&amp;nbsp; Right: Spherical harmonics visualization&lt;/em&gt;
&lt;/p&gt;

&lt;p&gt;This is important for achieving &lt;strong&gt;photorealistic rendering&lt;/strong&gt; with effects like:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Specular highlights&lt;/li&gt;
  &lt;li&gt;Soft shadows&lt;/li&gt;
  &lt;li&gt;View-dependent lighting changes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-what-are-spherical-harmonics&quot;&gt;🔸 What Are Spherical Harmonics?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Spherical Harmonics (SH)&lt;/strong&gt; are a series of &lt;strong&gt;orthogonal basis functions&lt;/strong&gt; defined on the surface of a sphere. You can think of them as the 3D analog of &lt;strong&gt;Fourier series&lt;/strong&gt; for functions on a sphere.&lt;/p&gt;

&lt;p&gt;They are indexed by:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Degree (l)&lt;/strong&gt;: controls the frequency (higher means more detail)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Order (m)&lt;/strong&gt;: varies from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-l&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+l&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-levels&quot;&gt;Example Levels:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;SH level 0 (SH0):&lt;/strong&gt; Only constant color (no view dependence)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SH level 1 (SH1):&lt;/strong&gt; Basic directional lighting (like Lambertian)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SH level 2 or 3+:&lt;/strong&gt; Captures more complex angular dependencies&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-sh-in-gaussian-splatting&quot;&gt;🔸 SH in Gaussian Splatting&lt;/h2&gt;

&lt;p&gt;Each 3D Gaussian stores:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Position, scale, rotation, opacity&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Spherical Harmonics coefficients for RGB appearance&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Instead of storing just a single RGB color, we store a &lt;strong&gt;set of SH coefficients per color channel&lt;/strong&gt;. When rendering:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Compute the &lt;strong&gt;viewing direction&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt; for each Gaussian.&lt;/li&gt;
  &lt;li&gt;Evaluate the &lt;strong&gt;SH basis functions&lt;/strong&gt; at direction &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt; to get a vector &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SH_basis(v)&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Compute the final color as a dot product:&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;color = Σ (c_i * SH_basis_i(v))   for i = 1..n
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;c_i&lt;/code&gt; are SH coefficients.&lt;/p&gt;

&lt;h2 id=&quot;-sh-level-examples&quot;&gt;🔸 SH Level Examples&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;SH Level&lt;/th&gt;
      &lt;th&gt;# Coefficients (per color)&lt;/th&gt;
      &lt;th&gt;What it Captures&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Constant color&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Directional diffuse lighting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Soft shadows, simple specular&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;Rich angular detail&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So if SH=2:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;You store 9 SH coefficients per color channel (27 total for RGB).&lt;/li&gt;
  &lt;li&gt;You can model how color changes with view angle in a smooth and efficient way.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-visual-example-simplified&quot;&gt;🔸 Visual Example (Simplified)&lt;/h2&gt;

&lt;p&gt;Imagine a glossy red ball:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Without SH (SH=0):&lt;/strong&gt; The ball is flat red from all directions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;With SH=1:&lt;/strong&gt; The ball appears brighter on the side facing the light source.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;With SH=2+:&lt;/strong&gt; The ball has soft reflections and looks more realistic as you move the camera.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-dummy-python-code-example&quot;&gt;🔸 Dummy Python Code Example&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.special&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sph_harm&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Dummy view direction (theta, phi) in spherical coordinates
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# angle from z-axis
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# angle from x-axis in x-y plane
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Compute SH basis up to degree l=2
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_sh_basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;basis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Y_lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sph_harm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Only real part used in graphics
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example SH coefficients for RGB (assuming SH2 = 9 coeffs per channel)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh_coeffs_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sh_coeffs_g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sh_coeffs_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Evaluate SH basis
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh_basis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_sh_basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Final RGB color (dot product of SH coefficients and SH basis)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh_coeffs_r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sh_basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh_coeffs_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sh_basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh_coeffs_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sh_basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;RGB color from SH: R=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, G=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, B=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This code shows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;How SH basis functions are computed using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scipy.special.sph_harm&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;How SH coefficients are applied to compute view-dependent color&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-summary&quot;&gt;🔸 Summary&lt;/h2&gt;

&lt;p&gt;In &lt;strong&gt;Gaussian Splatting&lt;/strong&gt;, Spherical Harmonics:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Encode how color/appearance changes with view direction&lt;/li&gt;
  &lt;li&gt;Provide a compact way to achieve realistic rendering&lt;/li&gt;
  &lt;li&gt;Are used per-splat (each Gaussian has its own SH coefficients)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can &lt;strong&gt;trade off quality vs speed&lt;/strong&gt; by choosing the SH level (e.g., SH=0 for fast rendering, SH=2+ for better realism).&lt;/p&gt;
</content>
 </entry>
 

</feed>
